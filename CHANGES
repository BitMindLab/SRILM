
Version History

0.90	29 Jun 95	first working code, n-gram models only

0.91	02 Aug 95	snapshot for fosler@icsi, minor bug fixes

0.92	13 Aug 95	added BayesMix, VarNgram LMs

0.93	27 Aug 95	included all LM95 code

0.94	13 Oct 95
	* new directory structure mirroring DECIPHER layout.
	* man pages added
	* added support for Decipher N-best list rescoring
	* added Null LM
	* added new utility scripts
	* bug fixes

0.95	08 Sep 96	as of WS96
	* added Trellis class, disambig program
	* added support for pause tokens (-pau-) in sentences
	  (these are ignored for sentence prob computation)
	* added -tolower mapping
	* added word reversal
	* made Ngram model reading much faster (optimized floating point parsing)
	* added template class for ngram count tries (to use either integer or
	  float count value)
	* added optional noise tag skipping
	* added SkipNgram model
	* added Witten-Bell backoff
	* ported to native Sun and SGI C++ compilers (see doc/c++porting-notes),
	* suppress log10(0.0) warnings

0.96	05 Jun 97
	* Honor -gtNmin parameter even when discounting of higher counts
	  is effectively disabled.  (Allows building maximum likelihood LMs
	  smoothed only by low-count ngram elimination.)
	* Ignore pauses and noise in nbest-lattice alignments (also added 
	  -noise option).
	* ngram now supports mixtures of up to 6 ngram models.
	* added HiddenSNgram LM.
	* warn about multiple uses of '-' file for input or output
	* zio now handles incomplete reading of compressed file without error
	* Fixed interaction between deletion and iterations
	* Fixed handling of OOVs in cache model
	* Fixed decipher nbest rescoring: we now duplicate even the 
	  roundoff errors incurred by bytelogs.  Also added -decipher flag
	  to ngram to allow replication of recognizer LM scores.
	  Also, takes into account that Decipher (incorrectly) applies WTW
	  even to pauses.
	* Enhanced decipher-rescore script to deal with NBestList2.0 format,
	  with -bytelog and -nodecipherlm options .
	* Added tools to convert bigram and trigram backoff LMs into 
	  Decipher PFSG format (pfsg-from-ngram).
	* Enable DecipherNgram models order higher than bigram
	  (ngram -decipher-order flag).  Default is still bigram.
	* Fixed bug that caused float command line arguments to be parsed
	  incorrectly on SunOS4 systems (missing declaration in system header).

0.97 	30 Aug 97	as of WS97
	* New programs: segment and segment-nbest (moved here from
	  development code).
	* Made low-level NgramLM access functions public
	  (findProb, findBOW, insertProb, insertBOW).
	* Fixed nbest-lattice to use normalized posterior word
	  probabilities in lattice.
	* NBest, nbest-lattice: added N-best error computation.
	* WordLattice, nbest-lattice: added lattice error computation.
	* WordLattice: base all alignments on edit distance costs defined
	  in WordAlign.h.
	* contextID() now also returns length of context used.
	  Added contextID() implementations for NullLM and BayesMix.
	* Fixed contextID() for Ngram: don't truncate context if BOW = 1.
	* Fixed SArray, LHash to avoid assignment operator on remove().
	* Fixed add-ppls, subtract-ppls to handle -ppl -debug 2 output.
	* Lots of memory management fixes.
	* SArrayIter and LHashIter now work even while underlying object is
	  being moved (as when containing data structure is enlarged).
	* Added HTK Lattice tool interface (htk/ directory).
	* Made Trellis into a template class.
	* Allow arbitrary n-gram orders with disambig(1).
	* Added forward-backward decoding and posterior probability computation
	  to disambig(1).
	* Added disambig -lmw and -mapw options.
	* Added HMMofNGrams model (ngram -hmm option).
	* VocabMap reader now warns about duplicate entries

0.98	18 April 98
	* Allow ngram to disable Decipher LM backoff hack, for rescoring
	  new exact lattices (ngram -decipher-nobackoff).
	* N-best list vocabulary is now always expanded dynamically
	  (no more OOVs in N-best lists).
	* Added wrapper script for nbest-lattice to compute nbest error rate
	  (nbest-error).
	* Skip ngrams exceeding model order when reading.
	* Fixed memory bug in generateSentence().
	* Changed libmisc to work with Tcl version > 7.
	* Compute word error correctly for empty nbest list.
	* Added ngram pruning based on model perplexity change
	  (ngram-count -prune and ngram -prune).
	* Old ngram -prune option renamed -varprune.
	* New lattice word error minimization (nbest-lattice -lattice-wer).
	* Fixed ngram -gen bug due to omissions in SunOS4 header files.
	* merge-batch-counts removes merged source files
	* Added ngram -prune-lowprobs function to do the work of
	  remove-lowprob-ngrams, but much faster and using less memory.
	* Added support for new Decipher NBestList2.0 format.
	* Added word error count and posterior probability fields to NBestHyp
	  structure.
	* Added optional factor argument to countSentence() (convenient
	  to compute fractional sufficient statistics for alternative
	  training methods).
	* Don't make special symbols (<s>, </s>, <unk>) member of SubVocab
	  by default.
	* Ported to gcc 2.8.1 .

0.99	31 July 1999
	* Added hidden-ngram (word-boundary tagger).
	* Removed line length limit for File object.
	* Added disambig -continuous flag.
	* Fixed backward computation in disambig (again).
	* Generalized compute-best-mix to N > 2 models
	* Added AdaptiveMix LM class
	* Added nbest-mix utility (interpolation of nbest posteriors)
	* Added ngram -unk flag to handle open-class LMs
	* Added disambig and hidden-ngram -text-map option
	* Script enhancements:
	  - New script to convert nbest-lattice word graphs to PFSG
	    (wlat-to-pfsg)
	  - Added switches include probabilities in wlat-to-dot and pfsg-to-dot
	    output.
	  - Conversion to/from AT&T FSM format: fsm-to-pfsg and pfsg-to-fsm
	* ngram -rescore and associated scripts no longer set a hyp 
	   probability to zero if it contains OOVs. Instead, the probability
	   is computed ignoring those words (more useful in practice).
	   A warning is output as always.
	* Added ngram-count -float-counts option.
	* Added build support for Linux/i686 platform.

1.00 	8 June 2000
	* Added ClassNgram class and ngram -classes option.
	* Capability to convert class ngrams into word ngrams.
	* New program ngram-class for automatic word class induction.
	* Fixed interaction of ngram -mix-lm -bayes with non-standard n-grams:
	  can now build an interpolation of the non-standard (hidden-event,
	  class-based, etc.) n-gram with the additional, standard n-grams.
	* Replaced LM.noiseTag with LM.noiseVocab (list of noise tags to
	  be ignored).  Tools now take -noise-vocab option (as well as -noise
	  for backward compatibility).
	* Made ngram -counts work for non-n-gram models.
	* Added nbest-lattice -posterior-{amw,lmw,wtw} options to compute
	  word posteriors with different weightings from the one used in
	  hypothesis ranking.  Also added -deletion-bias flag for explicit
	  control of del/ins errors (-use-mesh mode only).
	* NBest rescoring methods now have optional acoustic model weight
	  (defaulting to 1 as before).
	* New class RefList (list of reference transcripts).
	* New class NBestSet (set of N-Best lists).
	* NBest, NBestSet, and nbest-lattice optionally split multiwords into
	  their components on reading (-multiwords option).
	* New nbest-optimize tool for finding near-optimal score combination
	  weights for word error minimizing N-best rescoring.
	* New anti-ngram program, for computing posterior-weighted N-gram
	  counts from N-best lists.
	* New nbest-rover script allows ROVER-style combination of hypotheses
	  from multiple N-best lists.
	* New rescore-decipher -norescore option, to reformat N-best lists
	  without LM rescoring.
	* Fixed bugs related to missing <s> and </s> in change-lm-vocab and
	  make-ngram-pfsg.
	* Significant speedups in LMs involving dynamic programming
	  (HiddenNgram, DFNgram, HMMofNgrams) when interpolating with other 
	  models or running in "ngram -debug 2" mode.
	* Allow absolute discounting on fractional counts, for more
	  effective construction of models from fractional counts.
	* Added ngram-merge -float-counts option, and allow "-" (stdin) as
	  input file.
	* ngram-count ensures <s> unigram (with prob 0) is defined to avoid
	  breaking other programs.
	* Added make-abs-discount script to compute absolute discounting 
	  constants from Good-Turing statistics.
	* compute-sclite and compare-sclite now take -multiwords option to
	  split compound words prior to scoring.
	* Changed option handling so that unsigned option arguments are forced
	  to be non-negative.
	* Added Map2 (2D Map) class to libdstruct.
	* Much better string hash function (borrowed from Tcl).
	* New man pages: training-scripts(1), lm-scripts(1), ppl-scripts(1),
	  pfsg-scripts(1), nbest-scripts(1), lm-format(5), classes-format(5),
	  pfsg-format(5), nbest-format(5).

1.0.1	12 July 2000

	Functionality:

	* wordError() and nbest-lattice -dump-errors now also output the
	  location of deletions in the alignment (NOTE: possible code
	  incompatibility).
	* New reverse-ngram-counts script.

	Bug fixes:

	* Workarounds for shortcomings in Linux gcc, math library, and linker.
	* make-ngram-pfsg: don't ignore bigram states with zero BOW (bugfix).
	* nbest-rover: fixed problem with handling of + lines.

1.1	21 May 2001

	Functionality:

	* HiddenNgram class generalized to deal with disfluency-type events
	  that manipulate the N-gram context.
	* rescore-reweight script now accepts additional score directories
	  (and associated score weights) for combination of an arbitrary number
	  of knowledge sources.
	* Enhanced rescore-decipher functionality:
	  - Option -lm-only to produce output containing LM scores only
	  - Option -pretty to perform word mapping on the fly.
	  - Warn about and handle LM scores that are NaN.
	* New class VocabMultiMap, implementing dictionary-style mappings of
	  words to strings from another vocabulary.
	* Added support for pronunciation-based word alignments in
	  WordMesh and nbest-lattice -use-mesh .
	* Added nbest-lattice -keep-noise option to preserve pauses and noises
	  in alignments.
	* Support for multiwords: - make-multiword-pfsg expands PFSGs to use
	  multiwords (using AT&T FSM tools).
	  - multi-ngram expands N-gram LM to include multiwords.
	* Added support for Decipher Intlog scaled log probabilities.
	* Added ngram -seed option to initialize random sentence generation
	  (contributed by Eric Fosler).
	* New add-pauses-to-pfsg pause= and version= options to allow
	  generation of Nuance-compatible PFSGs (see man page for details).
	* The NBest class and scripts handle NBestList2.0 format containing
	  phone and/or state backtraces (by ignoring them).
	* Added Amoeba search option to nbest-optimize (contributed by
	  Dimitra Vergyri).
	* Added standard 1-best optimization mode to nbest-optimize.
	* wlat-to-pfsg script now also processes confusion networks output by
	  nbest-lattice -use-mesh .

	Bug fixes:

	* ngram -decipher-nobackoff now applies to the -lm ngram as well if
	  option -decipher is also specified.
	* ngram -expand-classes no longer dumps core when handling
	  "context-free" class expansions (though those aren't supported).
	* gawk path in scripts is now adjusted prior to installation
	  (/usr/bin/gawk for Linux, /usr/local/bin/gawk elsewhere).
	* Fixed numerical problems in nbest-rover/nbest-posteriors.
	* ngram-counts -float-counts behaved differently from equivalent
	  integer-count estimation;  both integer and float counts now use
	  the same estimation code.
	* Reduced memory requirements of nbest-optimize by about 25%.
	* Minor changes for gcc-2.95.3.

1.1.1	20 July 2001

	Functionality:

	* WordMesh: new interface to record reference word string in alignment.
	* nbest-lattice: confusion networks can now record reference words
	  if specified with -reference, and are preserved by -write/-read.
	* replace-words-with-classes now has option to process ngram count
	  files (have_counts=1).
	* merge-nbest: new utility to merge N-best hyps from multiple lists.
	* wlat-stats: new utility to compute statistics of word posterior
	  lattices.

	Bug fixes:

	* GT discounting: fixed anomaly due to different floating point
	  precision on x86 platforms.
	* anti-ngram(1): documented options previously omitted.
	* WordMesh: reading/writing of confusion networks now preserves 
	  total posterior mass.
	* Changed the hypothesis alignment order in nbest-optimize to be
	  more compatible with decoding in nbest-lattice: first align nbest
	  hyps in order of decreasing (initial) scores, then align reference.
	  nbest-optimize -no-reorder keeps the old behavior (with references
	  anchoring the alignment).  All scores and initial lambdas are now
	  used to compute initial posterior hyp probabilities to guide the
	  hypothesis alignment; thus, it now makes sense to restart an
	  optimization with partially optimized weights to revised the
	  alignments.
	* nbest-optimize now warns about missing or incomplete score files.
	* Fixed a memory access error in nbest-optimize -1best.
	* Fixed weight normalization in nbest-optimize when first element is 0.
	* Miscellaneous fixes for compile under RH Linux 7.0.

1.2	20 November 2001
	
	Functionality:

	* nbest-lattice -dictionary allows word alignments to be guided by
	  dictionary pronunciations.
	* nbest-lattice -use-mesh -record-hyps records the rank of N-best hyps
	  contributing to each word hypothesis in the confusion network.
	* nbest-lattice -no-rescore and -decipher-format options make it
	  more convenient as an N-best format conversion tool.
	* VocabDistance: new class and subclasses to represent distance metrics
	  (e.g., phonetic distance) over vocabularies.
	* WordMesh: output word hyps in order of decreasing posteriors.
	* WordMesh: reading/writing of confusion networks now includes hyp IDs
	  from alignment.
	* NBest/MultiAlign/WordMesh: support for keeping extra word-level 
	  information (NBeSTWordInfo).
	* nbest-lattice: unified single and multiple file processing.
	  New option -write-dir to write multiple output lattices.
	  New option -refs to supply multiple references.
	  Options -nbest-errors and -lattice-errors are replaced by 
	  switches -nbest-error/-lattice-error, in conjunction with
	  -references/-refs.  Outputs are now prefixed by utterance IDs
	  when processing multiple files.
	* nbest-lattice -nbest-backtrace enables processing of backtrace 
	  information from N-best lists; combined with -use-mesh this produces
	  sausages that contain word-level scores and alignment information,
	  as well as phone backtraces (see new wlat-format(5) man page).
	* wlat-stats script now also computes error statistics when processing
	  confusion networks with references.
	* nbest-rover now handles N-best lists in Decipher format.
	* hidden-ngram and disambig: new option -fw-only to use only forward
	  probabilities for posterior computation.
	* rescore-decipher -filter option to apply textual rewriting filters
	  to hypotheses before rescoring.
	* segment-nbest -write-nbest-dir option for dumping rescored N-best
	  lists to a directory instead of to stdout.
	* segment-nbest -start-tag and -end-tag options to insert tags at
	  margins of N-best hyps.

	Bug fixes:
		
	* WordMesh: computation of deletion costs using a dictionary distance
	  was completely bogus (only affected undocumented nbest-lattice
	  -dictionary option).
	* nbest-lattice: correctly process -nbest-files using -dictionary in
	  alignment.
	* nbest-rover: fixed to work on Linux 
	* hidden-ngram: don't abort when an event posterior is 0.
	* hidden-ngram: avoid abort when *noevent* occurs in -hidden-vocab list.
	* segment-nbest: now correctly uses ngram contexts longer than trigram.
	* segment-nbest: optimized -bias 0 case by disallowing sentence
	  boundary states altogether.
	* multi-ngram -prune-unseen-ngrams prevents insertion of multiword
	  N-grams whose component N-grams were not in the original model.
	* ngram: fixed computation of mixture lambda for second LM when three
	  or more models are interpolated.
	* nbest-posterior (and thus nbest-rover) no longer split multiwords by
	  themselves.  To split multiwords with nbest-rover, append the
	  -multiwords option to the argument list, which is passed on to
	  nbest-lattice to achieve the desired effect.
	* ngram -renorm now applies BEFORE class expansion or pruning of 
	  model (in case input model is unnormalized).
	* make-nbest-pfsg bug involving transition into final node fixed.
	* Minor script changes to avoid warnings with gawk 3.1.0.

1.3	11 February 2002
	
	Functionality:

	* Trellis class, disambig and hidden-ngram tools: added support for
	  N-best decoding (contributed by Anand Venkataraman).

	* MultiwordLM wrapper LM class as a convenient way to split multiwords
	  prior to LM evaluation.

	* New MultiwordVocab class to support MultiwordLM.

	* Added ngram -multiwords option (based on MultiwordLM wrapper).

	* Added support for Chen & Goodman's Modified Kneser-Ney smoothing
	  and interpolated backoff estimates.  See ngram-count options
	  -kndiscount[1-6], -kn[1-6], and interpolate[1-6].

	* New library and tool for lattice manipulation: lattice-tool.

	* New nbest-mix -set-am-scores and -set-lm-scores options. These allow
	setting either the AM or the LM scores in the N-best output to simulate
	the combined posteriors, while preserving the other scores.

	* Added some regression tests (test/ subdirectory).

	* Support for Windows via CYGWIN porting layer (MACHINE_TYPE=cygwin).
	See doc/README.windows for details.

	Bug fixes:

	* Trellis: deallocate old trellis nodes on demand in init(), rather
	  than preemptively in clear().  Greatly speeds up forward computation
	  for trellis-based LMs (e.g., ClassNgram).

	* Textstats: fix to handle zero denominator in ppl computation.

	* disambig: fixed off-by-one error indexing into trellis.

	* Miscellaneous small fixes for compilation and operation under Windows
	(using the CYGWIN environment).

	Warning: See doc/README.x86 about a gcc compiler bug that might 
	affect you on Intel platforms.

1.3.1	25 June 2002

	Functionality:

	* nbest-optimize -write-rover-control option conveniently dumps a
	control file for nbest-rover that encodes the optimized parameters.
	* New regression tests for nbest-rover (i.e., nbest-lattice) and
	nbest-optimize.
	* nbest-posteriors, combine-acoustic-scores now all handle and
	preserve Decipher nbest formats.  This allows nbest-rover to
	generate sausages with backtrace information if input nbest lists
	contain it (using -nbest-backtrace option).
	* New tool nbest-pron-score for computing pronunciation and pause LM
	scores from N-best hypotheses.
	* Added disambig -totals option to compute total string probabilities
	(same as in hidden-ngram).
	* reverse-lm: simple filter to reverse a bigram backoff LM.
	* lattice-tool -collapse-same-words reduces lattices by merging all
	nodes with identical words (but also creates new paths in lattice).
	* nbest-lattice -prime-with-refs option uses reference strings
	to improve sausage alignment.
	* compute-best-sentence-mix: new script to optimize sentence-level
	interpolation of LMs.
	* nbest-latttice -lattice-files option to align multiple word lattices;
	currently only works with -use-mesh (sausages).
	* hidden-ngram now supports mixture and class N-gram LMs.
	* New class SimpleClassNgram, a more efficient implementation of 
 	ClassNgram's where each word is assumed to belong to at most one
	class and class expansions are exactly one word long.
	Enabled by -simple-classes switch in ngram, lattice-tool, and 
	hidden-ngram.
	* ngram -counts now handles escaped input lines and LM state change
	directives embedded in the input.
	* New tool nbest-pron-score for scoring pronunciations and pauses in
	N-best hypotheses.
	* NgramStats::parseNgram() new function to parse N-gram counts from
	a character string.
	* LM::pplCountsFile() new function to evaluate LM on counts read from
	a file.

	Bug fixes:

	* make-ngram-pfsg is no longer limited to trigram models.
	* Avoid NaN values in disambig and hidden-ngram, in cases where lmw or
	mapw are zero and the corresponding log probabilities are -Infinity.
	* Avoid numerical problems in N-best posterior computation by using
	AddLogP() to compute normalizer.
	* anti-ngram no longer requires -refs argument with -all-ngrams.
	* Fixed bug removing noise from nbest lists with backtrace.
	* Code fixes for clean compiles with gcc 3.x.
	* nbest-rover more efficient by using a single invocation of
	nbest-lattice for all input nbest lists.
	* ClassNgram: fixed handling of words that appear as members of a class
	with zero probability, or have zero membership probability.
	* nbest-lattice -record-hyps now outputs hyp ids according to the 
	original nbest order, rather than the sorted one.
	* make-hiddens-lm now gives proper unigram probability to hidden-S tag.
	* Compute acoustic scores in Decipher N-best-2 format by subtracting
	token LM scores from total score.  This deals correctly with cases where
	the total scores have been adjusted by summing merged hyps, and are no
	longer the sum of all AC and LM word scores.
	* Gawk scripts that test for alphabetic or lowercase characters are
	more portable and handle non-ascii and multibyte characters.

	The package now includes a paper on SRILM, to appear in ICSLP-2002,
	that gives an overview of the software and its design (doc/paper.ps).

1.3.2	3 September 2002

	New functionality:
	
	* Added ngram-count and ngram-count -nonevents option to specify a 
	subset of words that are to be non-events, i.e., tokens that can only
	occur in contexts (such as <s>).
	* Extended ngram-count discounting options for up to 9-grams.
	* Added support in Vocab and Ngram classes for processing meta-counts
	(counts-of-counts).
	* Added ngram-count -meta-tag and -kn-counts-modified options to
	support make-big-lm.
	* Added ngram-count -read-with-mincounts flag to suppress counts
	below cuttoff thresholds at reading time.  This dramatically lowers
	memory consumption, and speeds up make-big-lm operation (which used 
	to use a gawk script for the same purpose).
	* Added option to specify vocabulary to add-pauses-to-pfsg for cases
	where heuristics fail.
	* lattice-tool can now handle arbitrary order LMs for expanding 
	lattices.  The old trigram expansion algorithm is still available 
	with -old-expansion; the compact trigram algorithm is unchanged with
	-compact-expansion.
	* To better support lattice expansion, two new functions have been
	added to the LM interface: contextID() takes an optional word
	argument, to compute the context needed to predict a specific word,
	and contextBOW() is a new interface to compute the backoff weight
	associated with truncating a history.
	* Added makefile support to generate executable versions that use
	"compact" data structures.  See item 9 in INSTALL for details, and
	doc/time-space-tradeoff for a simple benchmark result.

	Bug fixes:

	* Convert pseudo-log(0) value (-99) in DARPA backoff models back to
	true log(0) on reading.  This ensures that non-event words in the
	input are treated as zeroprobs (by the perplexity computation and
	otherwise).
	* Avoid NaN floating point results in N-best rescoring and
	nbest-optimize, by handling 0 * log(0) more carefully.
	* Handle -Inf AM and LM scores in SRILM N-best format.
	* make-big-lm was reworked to support KN in addition to GT discounting.
	Warning: the modified lower-order counts for KN are created using
	merge-batch-counts and can get almost as big as the original counts.
	Beware of the additional disk space and run time requirement!
	* Clear out old parameters before reading or estimating N-gram models.
	* Reading in new class definitions into ClassNgram object now deletes
	old definitions (unless classes file is empty).
	* Destructors for Ngram and ClassNgram now free N-gram and class 
	definition memory.
	* nbest-pron-score: avoid core dump when pronunciation information is
	missing from N-best list.
	* make-ngram-pfsg: fixed generation of unigram PFSGs.
	* Avoid use of toupper() in add-pauses-to-pfsg.
	* Handle ngram-count -order 0 and print warning.
	* Avoid using zcat in scripts since it behaves differently on different
	systems and depending on PATH setting.
	* nbest-lattice and nbest-optimize no longer strip a filename part
	following '.' to derive utterance ids; only known file suffixes
	are removed.
	* Fixed bugs in member declarations that were preventing TaggedVocab,
	TaggedNgramStats, and StopNgramStats from working correctly.
	* compute-sclite now ignores utterances with a reference of 
	"ignore_time_segment_in_scoring", consistent with NIST STM scoring.
	* Vocab.h now defines SArray_compareKey() for strings over VocabIndex,
	allowing use as keys in sorted arrays.
	* ClassNgram now uses the processed words as the context after an OOV.
	This works better when the input contains context cue tags.
	* i386-solaris platform was not being detected by machine-type script.

1.3.3	2 March 2003

	New functionality:

	* Increased maximum number of interpolated LMs in ngram, hidden-ngram,
	and lattice-tool to 10.
	* ngram now computes static interpolation (N-gram merging) of up to 10
	input LMs (consistent with handling of dynamic interpolation).
	* ngram and lattice-tool -limit-vocab option limits LM reading to
	those parameters that pertain to words specified by -vocab.
	The LM:read() function got an optional second argument for this
	purpose.  
	ngram -limit-vocab -renorm now effectively does the same as the 
	change-lm-vocab script.  However, the main purpose of -limit-vocab
	is to save memory by discarding N-grams that are not relevant to a 
	test set.
	* rescore-decipher -limit-vocab precomputes the vocabulary used by
	N-best lists and invokes ngram -limit-vocab to allow rescoring with 
	very large models on machines with little memory.
	* Ngram::mixProbs() now has version that destructively merges an Ngram
	into an existing model.  ngram -mix-lm now uses this version, instead
	of the old, non-destructive one, thereby achieving considerable time
	and space savings (only two models, rather than 3, have to be kept in
	memory at a time).
	* ngram-count and ngram -map-unk option, to change the "unknown" word
	token string.
	* compute-sclite, compare-sclite now understand multiple -S options to
	specify intersections of several utterance subsets for scoring.
	* make-batch-counts now ignores lines in input file list that start 
	with # (allowing comments in the file list).
	* Added replace-words-with-classes partial=1 option to prevent 
	multi-word replacements that include multiple whitespace characters
	(i.e., "a b" is only replaced with a single space between the words).
	* New LM script: sort-lm, reorders N-grams lexicographically, as 
	required by some other software (e.g., Sphinx3, pointed out by 
	Mikko Kurimo <mikkok@james.hut.fi>).
	* New training script: reverse-text, reverses word order in text file.
	* New pfsg script: pfsg-vocab, extracts vocabulary used in PFSGs.

	Bug fixes:

	* disambig and hidden-ngram -keep-unk now also causes LM to be
	treated as  open-vocabulary.
	* HiddenNgram class (debug level 2) was omitting the event after
	the last word from the Viterbi backtrace.
	* ngram -expand-classes was including -pau- word in expanded LM.
	* Made backoff computation in Ngram:wordProbBO() more efficient,
	avoiding multiple lookups in the context trie.  Gives about a 30%
	speedup in ngram -debug 3 -ppl.
	* ngram -lm reading is faster by about 8% due to a code optimization.
	* ngram-count -order 2 -kndiscount3 no longer aborts with an error.  
	The -order option effectively limits the discounting parameters
	computed, so that the model order can be changed without having to
	adjust the smoothing options.
	* make-big-lm -trust-totals option is ignored with KN discounting,
	they don't work well together.
	* make-big-lm now checks that input counts files are not stdin.
	* Reading N-best lists in Decipher format now sets the number-of-words
	score, so that weight rescoring, optimization etc. can use them.
	* ngram-count normalizes the N-gram probabilities for a context to 1
	if the backoff distribution for that context has probability mass 0.
	The latter can happen e.g. if all N-grams for a context have been
	observed and received discounted probabilities.  The fix ensures that
	the overall distribution is normalized in this case.
	* rescore-reweight now accepts Decipher N-best lists.
	* nbest-posteriors and nbest-rover now handle Decipher version 2
	N-best lists better (allowing LM and WT weights to be applied).
	* Initialize locale in all top-level programs.  disambig, hidden-ngram,
	segment, and segment-nbest were missing it, causing potential problems
	with non-ASCII characters.
	* nbest-lattice -write-vocab option to find vocabulary used in N-best
	list.
	* nbest-pron-score now uses idFromFilename() function to avoid 
	over-truncating filenames when inferring sentence ids.
	* Added more strippable filename suffixes in idFromFilename() function.
	* NBest: correctly read in phone backtraces that are time-reversed.
	* compute-oov-rate ignores -pau- tokens.
	* Various nbest scripts now process input directories containing links
	(rather than plain files) correctly.
	* Lattice class takes care to limit range of intlog transition
	probabilities in PFSG output, so as to avoid overflow when converting
	to bytelog scale.
	* make-ngram-pfsg removes temporary file (now placed in /tmp) even
	when killed by signal.
	* Hidden-event and DF N-gram models are documented in detail in ngram
	man page.
	* Test suite result comparisons against reference output now use a 
	script that ignores small numerical discrepancies, so as to produce 
	fewer false alarms.

	Portability:

	* Compiles under MacOS X (MACHINE_TYPE=macosx), thanks to help from
	wooters@icsi.berkeley.edu and jean-philippe.demoulin@enst.fr.

$Date: 2003/03/02 17:45:07 $

