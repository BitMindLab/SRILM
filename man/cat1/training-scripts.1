


training-scripts(1)                           training-scripts(1)


NNAAMMEE
       training-scripts,    compute-oov-rate,   continuous-ngram-
       count,   get-gt-counts,   make-abs-discount,   make-batch-
       counts,   make-big-lm,  make-diacritic-map,   make-gt-dis-
       counts,  merge-batch-counts,   replace-words-with-classes,
       reverse-ngram-counts, uniform-classes, vp2text - miscella-
       neous conveniences for language model training

SSYYNNOOPPSSIISS
       ggeett--ggtt--ccoouunnttss mmaaxx==_K oouutt==_n_a_m_e [_c_o_u_n_t_s...]
       mmaakkee--ggtt--ddiissccoouunnttss mmiinn==_m_i_n mmaaxx==_m_a_x _g_t_c_o_u_n_t_s
       mmaakkee--aabbss--ddiissccoouunntt _g_t_c_o_u_n_t_s
       mmaakkee--bbaattcchh--ccoouunnttss _f_i_l_e_-_l_i_s_t [_b_a_t_c_h_-_s_i_z_e [_f_i_l_t_e_r [_c_o_u_n_t_-_d_i_r
       [_o_p_t_i_o_n_s...]]]]
       mmeerrggee--bbaattcchh--ccoouunnttss _c_o_u_n_t_-_d_i_r [_f_i_l_e_-_l_i_s_t|_s_t_a_r_t_-_i_t_e_r]
       ccoonnttiinnuuoouuss--nnggrraamm--ccoouunntt [ oorrddeerr==_N ] [_t_e_x_t_f_i_l_e...]
       rreevveerrssee--nnggrraamm--ccoouunnttss [_c_o_u_n_t_s_-_f_i_l_e...]
       mmaakkee--bbiigg--llmm --nnaammee _n_a_m_e --rreeaadd _c_o_u_n_t_s --ttrruusstt--ttoottaallss --llmm _n_e_w_-
       _m_o_d_e_l [_o_p_t_i_o_n_s...]
       rreeppllaaccee--wwoorrddss--wwiitthh--ccllaasssseess ccllaasssseess==_c_l_a_s_s_e_s [oouuttffiillee==_c_o_u_n_t_s
       nnoorrmmaalliizzee==0|1 aaddddoonnee==_K] [_t_e_x_t_f_i_l_e...]
       uunniiffoorrmm--ccllaasssseess _c_l_a_s_s_e_s >>_n_e_w_-_c_l_a_s_s_e_s
       mmaakkee--ddiiaaccrriittiicc--mmaapp _v_o_c_a_b
       vvpp22tteexxtt [_t_e_x_t_f_i_l_e...]
       ccoommppuuttee--oooovv--rraattee _v_o_c_a_b [_c_o_u_n_t_s...]

DDEESSCCRRIIPPTTIIOONN
       These  scripts  perform  convenience tasks associated with
       the training of  language  models.   They  complement  and
       extend the basic N-gram model estimator in nnggrraamm--ccoouunntt(1).

       Since these tools are implemented as  scripts  they  don't
       automatically  input  or output compressed data files cor-
       rectly, unlike the main SRILM tools.  However, since  most
       scripts  work with data from standard input or to standard
       output (by leaving out the file argument, or specifying it
       as  ``-'')  it  is  easy to combine them with gguunnzziipp(1) or
       ggzziipp(1) on the command line.

       Also note that many of the scripts take their options with
       the ggaawwkk(1) syntax _o_p_t_i_o_n==_v_a_l_u_e instead of the more common
       --_o_p_t_i_o_n _v_a_l_u_e.

       ggeett--ggtt--ccoouunnttss  computes  the  counts-of-counts  statistics
       needed  in  Good-Turing  smoothing.   The  frequencies  of
       counts up to _K are computed (default is 10).  The  results
       are   stored   in  a  series  of  files  with  root  _n_a_m_e,
       _n_a_m_e..ggtt11ccoouunnttss, _n_a_m_e..ggtt22ccoouunnttss, ...,  _n_a_m_e..ggtt_Kccoouunnttss.   It
       is  assumed  that  the  input  counts  have  been properly
       merged, i.e., that there are no duplicated N-grams.

       mmaakkee--ggtt--ddiissccoouunnttss takes one of the output files of ggeett--ggtt--
       ccoouunnttss  and  computes  the  corresponding Good-Turing dis-
       counting factors.  The output can then be passed to nnggrraamm--



SRILM Tools        $Date: 2000/06/22 20:48:33 $                 1





training-scripts(1)                           training-scripts(1)


       ccoouunntt(1)  via  the  --ggtt_K  options to control the smoothing
       during model estimation.  Precomputing the GT  discounting
       in  this  fashion has the advantage that the GT statistics
       are not affected  by  restricting  N-grams  to  a  limited
       vocabulary.    Also,  ggeett--ggtt--ccoouunnttss/mmaakkee--ggtt--ddiissccoouunnttss  can
       process arbitrarily large count files, since they  do  not
       need  to read the counts into memory (unlike nnggrraamm--ccoouunntt).

       mmaakkee--aabbss--ddiissccoouunntt computes the absolute  discounting  con-
       stant  needed  for  the  nnggrraamm--ccoouunntt  --ccddiissccoouunntt_K options.
       Input is one of the files produced by ggeett--ggtt--ccoouunnttss.

       mmaakkee--bbaattcchh--ccoouunnttss performs the first  stage  in  the  con-
       struction  of very large N-gram count files.  _f_i_l_e_-_l_i_s_t is
       a list of input text files.  These files will  be  grouped
       into batches of size _b_a_t_c_h_-_s_i_z_e (default 10) that are then
       processed in one run of  nnggrraamm--ccoouunntt  each.   For  maximum
       performance,  _b_a_t_c_h_-_s_i_z_e  should  be  as large as possible
       without triggering paging.  Optionally, a _f_i_l_t_e_r script or
       program can be given to condition the input texts.  The N-
       gram  count  files  are  left   in   directory   _c_o_u_n_t_-_d_i_r
       (``counts'' by default), where they can be found by a sub-
       sequent run of mmeerrggee--bbaattcchh--ccoouunnttss.  All following  _o_p_t_i_o_n_s
       are  passed to nnggrraamm--ccoouunntt, e.g., to control N-gram order,
       vocabulary, etc.  (no options triggering model  estimation
       should be included).

       mmeerrggee--bbaattcchh--ccoouunnttss  completes  the  construction  of large
       count files by merging the batched counts left  in  _c_o_u_n_t_-
       _d_i_r  until a single count file is produced.  Optionally, a
       _f_i_l_e_-_l_i_s_t of count files to combine can be specified; oth-
       erwise  all  count  files in _c_o_u_n_t_-_d_i_r from a prior run of
       mmaakkee--bbaattcchh--ccoouunnttss will be  merged.   A  number  as  second
       argument  restarts the merging process at iteration _s_t_a_r_t_-
       _i_t_e_r.  This is convenient if merging fails to complete for
       some reason (e.g., for temporary lack of disk space).

       ccoonnttiinnuuoouuss--nnggrraamm--ccoouunntt  generates  N-grams  that span line
       breaks (which are usually  taken  to  be  sentence  bound-
       aries).  To count N-grams across line breaks use
            continuous-ngram-count _t_e_x_t_f_i_l_e | ngram-count -read -
       The argument _N  controls  the  order  of  N-grams  counted
       (default 3), and should match  the argument of nnggrraamm--ccoouunntt
       --oorrddeerr.

       rreevveerrssee--nnggrraamm--ccoouunnttss reverses the word order of N-grams in
       a counts file or stream.  For example, to recompute lower-
       order counts from higher-order ones, but do the  summation
       over  preceding  words (rather than following words, as in
       nnggrraamm--ccoouunntt(1)), use
            reverse-ngram-counts _c_o_u_n_t_-_f_i_l_e | \
            ngram-count -read - -recompute -write - | \
            reverse-ngram-counts > _n_e_w_-_c_o_u_n_t_s




SRILM Tools        $Date: 2000/06/22 20:48:33 $                 2





training-scripts(1)                           training-scripts(1)


       mmaakkee--bbiigg--llmm constructs large N-gram models in a more  mem-
       ory-efficient  way than nnggrraamm--ccoouunntt by itself.  It does so
       by precomputing the Good-Turing smoothing  parameters  and
       passing  nnggrraamm--ccoouunntt  only  a subset of the counts, namely
       those of N-grams to be retained in the  model.   The  _n_a_m_e
       parameter is used to name various auxiliary files.  _c_o_u_n_t_s
       contains the raw N-gram counts; it may by (and usually is)
       a  compressed  file.  If the file contains complete lower-
       order counts corresponding to  the  sums  of  higher-order
       counts, then the --ttrruusstt--ttoottaallss options should be given for
       efficiency.  All other _o_p_t_i_o_n_s are passed  to  nnggrraamm--ccoouunntt
       (only options affecting model estimation should be given).

       rreeppllaaccee--wwoorrddss--wwiitthh--ccllaasssseess  replaces  expansions  of  word
       classes  with  the  corresponding  class  labels.  _c_l_a_s_s_e_s
       specifies class expansions in ccllaasssseess--ffoorrmmaatt(5).  Ambigui-
       ties  are  resolved  in favor of the longest matching word
       strings.  Ties are broken in favor of the expansion listed
       first  in  _c_l_a_s_s_e_s_.   Optionally,  the  file  _c_o_u_n_t_s  will
       receive the expansion counts resulting from  the  replace-
       ments.   nnoorrmmaalliizzee==00  or  11  indicates  whether the counts
       should be normalized to probabilities (default is 1).  The
       aaddddoonnee  option  may be used to smooth the expansion proba-
       bilities by adding _K to each count (default 1).

       uunniiffoorrmm--ccllaasssseess takes a file in ccllaasssseess--ffoorrmmaatt(5) and adds
       uniform  probabilities  to  expansions  that  don't have a
       probability explicitly stated.

       mmaakkee--ddiiaaccrriittiicc--mmaapp constructs a map  file  that  pairs  an
       ASCII-fied  version  of  the  words  in _v_o_c_a_b with all the
       occurring non-ASCII word forms.  Such a map file can  then
       be  used  with  ddiissaammbbiigg(1) and a language model to recon-
       struct the non-ASCII word form  with  diacritics  from  an
       ASCII text.

       vvpp22tteexxtt  is  a  reimplementation of the filter used in the
       DARPA Hub-3 and Hub-4 CSR evaluations to convert ``verbal-
       ized  punctuation'' texts to language model training data.

       ccoommppuuttee--oooovv--rraattee determines the out-of-vocabulary rate  of
       a  corpus  from its unigram _c_o_u_n_t_s and a target vocabulary
       list in _v_o_c_a_b.

SSEEEE AALLSSOO
       ngram-count(1), classes-format(5), disambig(1).

BBUUGGSS
       Some of the tools could be generalized  and/or  made  more
       robust to misuse.

AAUUTTHHOORR
       Andreas Stolcke <stolcke@speech.sri.com>.
       Copyright 1995-1999 SRI International



SRILM Tools        $Date: 2000/06/22 20:48:33 $                 3


