nbest-optimize(1)                               nbest-optimize(1)



NNAAMMEE
       nbest-optimize  -  optimize  score  combination for N-best
       word error minimization

SSYYNNOOPPSSIISS
       nnbbeesstt--ooppttiimmiizzee [--hheellpp] option ...  [ _s_c_o_r_e_d_i_r ...  ]

DDEESSCCRRIIPPTTIIOONN
       nnbbeesstt--ooppttiimmiizzee reads a set  of  N-best  lists,  additional
       score  files,  and corresponding reference transcripts and
       optimizes the score combination weights so as to  minimize
       the  word  error  of a classifier that performs word-level
       posterior probability maximization.  The optimized weights
       are  meant  to be used with nnbbeesstt--llaattttiiccee(1) and the --uussee--
       mmeesshh  option,  or  the  nnbbeesstt--rroovveerr  script  (see   nnbbeesstt--
       ssccrriippttss(1)).  nnbbeesstt--ooppttiimmiizzee determines both the best rel-
       ative weighting of knowledge source scores and the optimal
       --ppoosstteerriioorr--ssccaallee parameter that controls the peakedness of
       the posterior distribution.

       The optimization is performed by  gradient  descent  on  a
       smoothed  (sigmoidal)  approximation  of the true 0/1 word
       error function (Katagiri et  al.  1990).   Therefore,  the
       result  can  only be expected to be a _l_o_c_a_l minimum of the
       error surface.  (A more global search can be attempted  by
       specifying different starting points.)  Another approxima-
       tion is that the error function  is  computed  assuming  a
       fixed  multiple alignment of all N-best hypotheses and the
       reference string, which tends to slightly overestimate the
       true  pairwise error between any single hypothesis and the
       reference.

       An  alternative  search  strategy  uses  a   simplex-based
       "Amoeba"  search on the (non-smoothed) word error function
       (Press et al. 1988).  The  search  is  restarted  multiple
       times to avoid local minima.

       Alternatively,  nnbbeesstt--ooppttiimmiizzee  can  also optimize weights
       for a standard, 1-best hypothesis rescoring  that  selects
       entire  (sentence)  hypotheses  (--11bbeesstt  option).  In this
       mode sentence-level error counts may be read from external
       files,  or computed on the fly from the reference strings.
       The weights obtained are meant to be used for N-best  list
       rescoring with rreessccoorree--rreewweeiigghhtt (see nnbbeesstt--ssccrriippttss(1)).

       Each  filename  argument  can  be an ASCII file, or a com-
       pressed file (name ending in .Z or .gz), or ``-'' to indi-
       cate stdin/stdout.

OOPPTTIIOONNSS
       --hheellpp  Print option summary.

       --ddeebbuugg _l_e_v_e_l
              Controls  the  amount  of  output  (the  higher the
              _l_e_v_e_l, the more).  At level 1, error statistics  at
              each  iteration  are  printed.   At  level  2, word
              alignments are printed.  At  level  3,  full  score
              matrix  is  printed.  At level 4, detailed informa-
              tion about word hypothesis ranking is  printed  for
              each training iteration and sample.

       --nnbbeesstt--ffiilleess _f_i_l_e_-_l_i_s_t
              Specifies  the  set  of  N-best  files as a list of
              filenames.   Three  sets  of  standard  scores  are
              extracted from the N-best files: the acoustic model
              score, the language model score, and the number  of
              words  (for  insertion  penalty  computation).  See
              nnbbeesstt--ffoorrmmaatt(5) for details.

       --rreeffss _r_e_f_e_r_e_n_c_e_s
              Specifies the reference transcripts.  Each line  in
              _r_e_f_e_r_e_n_c_e_s  must  contain the sentence ID (the last
              component in the N-best filename  path,  minus  any
              suffixes) followed by zero or more reference words.

       --11bbeesstt Select  optimization  for  standard  sentence-level
              hypothesis selection.

       --eerrrroorrss _d_i_r
              In  1-best mode, optimize for error counts that are
              stored in separate files in directory _d_i_r.  Each N-
              best list must have a matching error counts file of
              the same basename in _d_i_r.   Each  file  contains  7
              columns of numbers in the format
                   wcr wer nerr nsub ndel nins nw
              Only the 3rd column (number of errors) and the last
              column (number of reference  words) is used by  the
              program.
              If  this option is omitted, errors will be computed
              from the N-best hypotheses and the reference  tran-
              scripts.

       --mmaaxx--nnbbeesstt _n
              Limits  the  number of hypotheses read from each N-
              best list to the first _n.

       --rreessccoorree--llmmww _l_m_w
              Sets the language model weight  used  in  combining
              the  language model log probabilities with acoustic
              log probabilities.  This is used to compute initial
              aggregate hypotheses scores.

       --rreessccoorree--wwttww _w_t_w
              Sets  the word transition weight used to weight the
              number of words relative to the acoustic log proba-
              bilities.   This  is used to compute initial aggre-
              gate hypotheses scores.

       --ppoosstteerriioorr--ssccaallee _s_c_a_l_e
              Initial value  for  scaling  log  posteriors.   The
              total  weighted  log score is divided by _s_c_a_l_e when
              computing normalized posterior probabilities.  This
              controls  the peakedness of the posterior distribu-
              tion.  The default value is whatever was chosen for
              --rreessccoorree--llmmww,  so  that  language  model scores are
              scaled to have weight 1, and acoustic  scores  have
              weight 1/_l_m_w.

       --vvooccaabb _f_i_l_e
              Read  the  N-best  list vocabulary from _f_i_l_e.  This
              option is mostly redundant since words found in the
              N-best  input  are  implicitly added to the vocabu-
              lary.

       --ttoolloowweerr
              Map vocabulary to lowercase, eliminating case  dis-
              tinctions.

       --mmuullttiiwwoorrddss
              Split  multiwords  (words joined by '_') into their
              components when reading N-best lists.

       --nnoo--rreeoorrddeerr
              Do not reorder the hypotheses  for  alignment,  and
              start  the alignment with the reference words.  The
              default is to first align hypotheses  by  order  of
              decreasing  scores  (according to the initial score
              weighting) and then the reference,  which  is  more
              compatible with how nnbbeesstt--llaattttiiccee(1) operates.

       --nnooiissee _n_o_i_s_e_-_t_a_g
              Designate _n_o_i_s_e_-_t_a_g as a vocabulary item that is to
              be ignored in aligning hypotheses with  each  other
              (the  same  as  the -pau- word).  This is typically
              used to identify a noise marker.

       --nnooiissee--vvooccaabb _f_i_l_e
              Read several noise tags from _f_i_l_e, instead  of,  or
              in  addition  to, the single noise tag specified by
              --nnooiissee.

       --iinniitt--llaammbbddaass _'_w_1 _w_2 _._._._'
              Initialize the score weights to the  values  speci-
              fied (zeros are filled in for missing values).  The
              default is to set the initial acoustic model weight
              to  1, the language model weight from --rreessccoorree--llmmww,
              the word transition weight from  --rreessccoorree--wwttww,  and
              all remaining weights to zero initially.  Prefixing
              a value with an equal sign (`=')  holds  the  value
              constant  during  optimization.  (All values should
              be enclosed in quotes to form a single command-line
              argument.)
              Hypotheses  are  aligned using the initial weights;
              thus, it makes sense  to  reoptimize  with  initial
              weights  from  a  previous optimization in order to
              obtain alignments closer to the optimimum.

       --aallpphhaa _a
              Controls the error function smoothness; the sigmoid
              slope parameter is set to _a.

       --eeppssiilloonn _e
              The  step-size used in gradient descent (the multi-
              ple of the gradient vector).

       --mmiinn--lloossss _x
              Sets the loss function for a sample effectively  to
              zero when its value falls below _x.

       --mmaaxx--ddeellttaa _d
              Ignores  the contribution of a sample to the gradi-
              ent if the derivative exceeds _d.  This helps  avoid
              numerical problems.

       --mmaaxxiitteerrss _m
              Stops  optimization  after _m iterations.  In Amoeba
              search, this limits the total number of  points  in
              the parameter space that are evaluated.

       --mmaaxx--bbaadd--iitteerrss n
              Stops  optimization after _n iterations during which
              the actual (non-smoothed) error has not  decreased.

       --mmaaxx--aammooeebbaa--rreessttaarrttss r
              Perform only up to _r repeated Amoeba searches.  The
              default is to search until _D searches give the same
              results, where _D is the dimensionality of the prob-
              lem.

       --eeppssiilloonn--sstteeppddoowwnn _s

       --mmiinn--eeppssiilloonn _m
              If _s is a value greater  than  zero,  the  learning
              rate  will  be multiplied by _s every time the error
              does not decrease  after  a  number  of  iterations
              specified  by  --mmaaxx--bbaadd--iitteerrss.  Training stops when
              the learning rate falls below _m in this manner.

       --ccoonnvveerrggee _x
              Stops optimization when the (smoothed)  loss  func-
              tion  changes  relatively  by  less than _x from one
              iteration to the next.

       --qquuiicckkpprroopp
              Use the approximate second-order  method  known  as
              "QuickProp" (Fahlman 1989).

       --iinniitt--aammooeebbaa--ssiimmpplleexx _'_s_1 _s_2 _._._._'
              Defines  the  step size for the initial Amoeba sim-
              plex.  One value for each non-fixed  search  dimen-
              sion  should  be specified, plus optionally a value
              for  the  posterior  scaling  parameter  (which  is
              searched as an added dimension).

       --pprriinntt--hhyyppss _f_i_l_e
              Write  the best word hypotheses to _f_i_l_e after opti-
              mization.

       --wwrriittee--rroovveerr--ccoonnttrrooll _f_i_l_e
              Writes a control  file  for  nnbbeesstt--rroovveerr  to  _f_i_l_e,
              reflecting  the  names of the input directories and
              the optimized parameter values.  The format of _f_i_l_e
              is  described  in  nnbbeesstt--ssccrriippttss(1).   The  file is
              rewritten for each new minimal error weight  combi-
              nation found.

       ----     Signals  the  end  of  options, such that following
              command-line arguments  are  interpreted  as  addi-
              tional scorefiles even if they start with `-'.

       _s_c_o_r_e_d_i_r...
              Any  additional arguments name directories contain-
              ing further score files.  In each directory,  there
              must  exist one file named after the sentence ID it
              corresponds to (the file may also  end  in  ``.gz''
              and  contain compressed data).  The total number of
              score dimensions is thus 3 (for the standard scores
              from the N-best list) plus the number of additional
              score directories specified.

SSEEEE AALLSSOO
       nbest-lattice(1), nbest-scripts(1), nbest-format(5).
       S. Katagiri, C.H. Lee, & B.-H. Juang, "A Generalized Prob-
       abilistic  Descent Method", in _P_r_o_c_e_e_d_i_n_g_s _o_f _t_h_e _A_c_o_u_s_t_i_-
       _c_a_l _S_o_c_i_e_t_y _o_f _J_a_p_a_n_, _F_a_l_l _M_e_e_t_i_n_g, pp. 141-142, 1990.
       S. E. Fahlman, "Faster-Learning Variations on  Back-Propa-
       gation: An Empirical Study", in D. Touretzky, G. Hinton, &
       T. Sejnowski (eds.), _P_r_o_c_e_e_d_i_n_g_s _o_f _t_h_e _1_9_8_8 _C_o_n_n_e_c_t_i_o_n_i_s_t
       _M_o_d_e_l_s _S_u_m_m_e_r _S_c_h_o_o_l, pp. 38-51, Morgan Kaufmann, 1989.
       W.  H.  Press,  B.  P.  Flannery, S. A. Teukolsky, & W. T.
       Vetterling, _N_u_m_e_r_i_c_a_l _R_e_c_i_p_e_s _i_n _C_: _T_h_e _A_r_t _o_f  _S_c_i_e_n_t_i_f_i_c
       _C_o_m_p_u_t_i_n_g, Cambridge University Press, 1988.

BBUUGGSS
       Gradient-based  optimization  is  not  supported  (yet) in
       1-best mode; use simplex-search optimization instead.
       The N-best directory in the control file output by --wwrriittee--
       rroovveerr--ccoonnttrrooll  is  inferred from the first N-best filename
       specified with --nnbbeesstt--ffiilleess, and will therefore only  work
       if all N-best lists are placed in the same directory.

AAUUTTHHOORRSS
       Andreas Stolcke <stolcke@speech.sri.com>
       Dimitra Vergyri <dverg@speech.sri.com>
       Copyright 2000-2002 SRI International



SRILM Tools        $Date: 2002/02/23 23:12:29 $ nbest-optimize(1)
